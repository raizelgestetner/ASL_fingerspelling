{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raizelgestetner/ASL_fingerspelling/blob/main/photo2parquet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding some text"
      ],
      "metadata": {
        "id": "9hYwDhxklOrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enoyeVOVZsfu",
        "outputId": "06adb47e-4f36-47a1-9591-7c3f8629ce25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiIF3BGWj_YP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dfafb08-f65a-43c2-a5f7-0b5c40d6d487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.5.26)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.25.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.9 sounddevice-0.4.6\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "import subprocess\n",
        "import time\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "-tcnkvm-kBaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_holistic = mp.solutions.holistic"
      ],
      "metadata": {
        "id": "6OTRHQn2kKus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns = [\"x_face_0\", \"x_face_61\", \"x_face_185\", \"x_face_40\", \"x_face_39\", \"x_face_37\", \"x_face_267\", \"x_face_269\", \"x_face_270\", \"x_face_409\", \"x_face_291\", \"x_face_146\", \"x_face_91\", \"x_face_181\", \"x_face_84\", \"x_face_17\", \"x_face_314\", \"x_face_405\", \"x_face_321\", \"x_face_375\", \"x_face_78\", \"x_face_191\", \"x_face_80\", \"x_face_81\", \"x_face_82\", \"x_face_13\", \"x_face_312\", \"x_face_311\", \"x_face_310\", \"x_face_415\", \"x_face_95\", \"x_face_88\", \"x_face_178\", \"x_face_87\", \"x_face_14\", \"x_face_317\", \"x_face_402\", \"x_face_318\", \"x_face_324\", \"x_face_308\", \"x_left_hand_0\", \"x_left_hand_1\", \"x_left_hand_2\", \"x_left_hand_3\", \"x_left_hand_4\", \"x_left_hand_5\", \"x_left_hand_6\", \"x_left_hand_7\", \"x_left_hand_8\", \"x_left_hand_9\", \"x_left_hand_10\", \"x_left_hand_11\", \"x_left_hand_12\", \"x_left_hand_13\", \"x_left_hand_14\", \"x_left_hand_15\", \"x_left_hand_16\", \"x_left_hand_17\", \"x_left_hand_18\", \"x_left_hand_19\", \"x_left_hand_20\", \"x_right_hand_0\", \"x_right_hand_1\", \"x_right_hand_2\", \"x_right_hand_3\", \"x_right_hand_4\", \"x_right_hand_5\", \"x_right_hand_6\", \"x_right_hand_7\", \"x_right_hand_8\", \"x_right_hand_9\", \"x_right_hand_10\", \"x_right_hand_11\", \"x_right_hand_12\", \"x_right_hand_13\", \"x_right_hand_14\", \"x_right_hand_15\", \"x_right_hand_16\", \"x_right_hand_17\", \"x_right_hand_18\", \"x_right_hand_19\", \"x_right_hand_20\", \"x_face_1\", \"x_face_2\", \"x_face_98\", \"x_face_327\", \"x_face_33\", \"x_face_7\", \"x_face_163\", \"x_face_144\", \"x_face_145\", \"x_face_153\", \"x_face_154\", \"x_face_155\", \"x_face_133\", \"x_face_246\", \"x_face_161\", \"x_face_160\", \"x_face_159\", \"x_face_158\", \"x_face_157\", \"x_face_173\", \"x_face_263\", \"x_face_249\", \"x_face_390\", \"x_face_373\", \"x_face_374\", \"x_face_380\", \"x_face_381\", \"x_face_382\", \"x_face_362\", \"x_face_466\", \"x_face_388\", \"x_face_387\", \"x_face_386\", \"x_face_385\", \"x_face_384\", \"x_face_398\", \"x_pose_12\", \"x_pose_14\", \"x_pose_16\", \"x_pose_18\", \"x_pose_20\", \"x_pose_22\", \"x_pose_11\", \"x_pose_13\", \"x_pose_15\", \"x_pose_17\", \"x_pose_19\", \"x_pose_21\", \"y_face_0\", \"y_face_61\", \"y_face_185\", \"y_face_40\", \"y_face_39\", \"y_face_37\", \"y_face_267\", \"y_face_269\", \"y_face_270\", \"y_face_409\", \"y_face_291\", \"y_face_146\", \"y_face_91\", \"y_face_181\", \"y_face_84\", \"y_face_17\", \"y_face_314\", \"y_face_405\", \"y_face_321\", \"y_face_375\", \"y_face_78\", \"y_face_191\", \"y_face_80\", \"y_face_81\", \"y_face_82\", \"y_face_13\", \"y_face_312\", \"y_face_311\", \"y_face_310\", \"y_face_415\", \"y_face_95\", \"y_face_88\", \"y_face_178\", \"y_face_87\", \"y_face_14\", \"y_face_317\", \"y_face_402\", \"y_face_318\", \"y_face_324\", \"y_face_308\", \"y_left_hand_0\", \"y_left_hand_1\", \"y_left_hand_2\", \"y_left_hand_3\", \"y_left_hand_4\", \"y_left_hand_5\", \"y_left_hand_6\", \"y_left_hand_7\", \"y_left_hand_8\", \"y_left_hand_9\", \"y_left_hand_10\", \"y_left_hand_11\", \"y_left_hand_12\", \"y_left_hand_13\", \"y_left_hand_14\", \"y_left_hand_15\", \"y_left_hand_16\", \"y_left_hand_17\", \"y_left_hand_18\", \"y_left_hand_19\", \"y_left_hand_20\", \"y_right_hand_0\", \"y_right_hand_1\", \"y_right_hand_2\", \"y_right_hand_3\", \"y_right_hand_4\", \"y_right_hand_5\", \"y_right_hand_6\", \"y_right_hand_7\", \"y_right_hand_8\", \"y_right_hand_9\", \"y_right_hand_10\", \"y_right_hand_11\", \"y_right_hand_12\", \"y_right_hand_13\", \"y_right_hand_14\", \"y_right_hand_15\", \"y_right_hand_16\", \"y_right_hand_17\", \"y_right_hand_18\", \"y_right_hand_19\", \"y_right_hand_20\", \"y_face_1\", \"y_face_2\", \"y_face_98\", \"y_face_327\", \"y_face_33\", \"y_face_7\", \"y_face_163\", \"y_face_144\", \"y_face_145\", \"y_face_153\", \"y_face_154\", \"y_face_155\", \"y_face_133\", \"y_face_246\", \"y_face_161\", \"y_face_160\", \"y_face_159\", \"y_face_158\", \"y_face_157\", \"y_face_173\", \"y_face_263\", \"y_face_249\", \"y_face_390\", \"y_face_373\", \"y_face_374\", \"y_face_380\", \"y_face_381\", \"y_face_382\", \"y_face_362\", \"y_face_466\", \"y_face_388\", \"y_face_387\", \"y_face_386\", \"y_face_385\", \"y_face_384\", \"y_face_398\", \"y_pose_12\", \"y_pose_14\", \"y_pose_16\", \"y_pose_18\", \"y_pose_20\", \"y_pose_22\", \"y_pose_11\", \"y_pose_13\", \"y_pose_15\", \"y_pose_17\", \"y_pose_19\", \"y_pose_21\", \"z_face_0\", \"z_face_61\", \"z_face_185\", \"z_face_40\", \"z_face_39\", \"z_face_37\", \"z_face_267\", \"z_face_269\", \"z_face_270\", \"z_face_409\", \"z_face_291\", \"z_face_146\", \"z_face_91\", \"z_face_181\", \"z_face_84\", \"z_face_17\", \"z_face_314\", \"z_face_405\", \"z_face_321\", \"z_face_375\", \"z_face_78\", \"z_face_191\", \"z_face_80\", \"z_face_81\", \"z_face_82\", \"z_face_13\", \"z_face_312\", \"z_face_311\", \"z_face_310\", \"z_face_415\", \"z_face_95\", \"z_face_88\", \"z_face_178\", \"z_face_87\", \"z_face_14\", \"z_face_317\", \"z_face_402\", \"z_face_318\", \"z_face_324\", \"z_face_308\", \"z_left_hand_0\", \"z_left_hand_1\", \"z_left_hand_2\", \"z_left_hand_3\", \"z_left_hand_4\", \"z_left_hand_5\", \"z_left_hand_6\", \"z_left_hand_7\", \"z_left_hand_8\", \"z_left_hand_9\", \"z_left_hand_10\", \"z_left_hand_11\", \"z_left_hand_12\", \"z_left_hand_13\", \"z_left_hand_14\", \"z_left_hand_15\", \"z_left_hand_16\", \"z_left_hand_17\", \"z_left_hand_18\", \"z_left_hand_19\", \"z_left_hand_20\", \"z_right_hand_0\", \"z_right_hand_1\", \"z_right_hand_2\", \"z_right_hand_3\", \"z_right_hand_4\", \"z_right_hand_5\", \"z_right_hand_6\", \"z_right_hand_7\", \"z_right_hand_8\", \"z_right_hand_9\", \"z_right_hand_10\", \"z_right_hand_11\", \"z_right_hand_12\", \"z_right_hand_13\", \"z_right_hand_14\", \"z_right_hand_15\", \"z_right_hand_16\", \"z_right_hand_17\", \"z_right_hand_18\", \"z_right_hand_19\", \"z_right_hand_20\", \"z_face_1\", \"z_face_2\", \"z_face_98\", \"z_face_327\", \"z_face_33\", \"z_face_7\", \"z_face_163\", \"z_face_144\", \"z_face_145\", \"z_face_153\", \"z_face_154\", \"z_face_155\", \"z_face_133\", \"z_face_246\", \"z_face_161\", \"z_face_160\", \"z_face_159\", \"z_face_158\", \"z_face_157\", \"z_face_173\", \"z_face_263\", \"z_face_249\", \"z_face_390\", \"z_face_373\", \"z_face_374\", \"z_face_380\", \"z_face_381\", \"z_face_382\", \"z_face_362\", \"z_face_466\", \"z_face_388\", \"z_face_387\", \"z_face_386\", \"z_face_385\", \"z_face_384\", \"z_face_398\", \"z_pose_12\", \"z_pose_14\", \"z_pose_16\", \"z_pose_18\", \"z_pose_20\", \"z_pose_22\", \"z_pose_11\", \"z_pose_13\", \"z_pose_15\", \"z_pose_17\", \"z_pose_19\", \"z_pose_21\"]"
      ],
      "metadata": {
        "id": "9ag867WC_PFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/\""
      ],
      "metadata": {
        "id": "Jg6YpJhN5_n1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compress video before runnign MediaPipe:\n",
        "reduce amount of frames and pixels"
      ],
      "metadata": {
        "id": "tnnI6Mt1oBoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/\"\n",
        "start_time = time.time()\n",
        "video_path = prefix + 'video.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "COMPRESS_NUM_FRAMES = 2    # take one frame from each COMPRESS_NUM_FRAMES\n",
        "COMPRESS_PIXELS = 1      # divide amount of pixels by COMPRESS_PIXELS\n",
        "FRAMES_PER_SHORT_VIDEO = 150\n",
        "FRAMES_OVERLAP = 50\n",
        "if total_frames // COMPRESS_NUM_FRAMES < 15:   # min num of frames for detection is 15\n",
        "  COMPRESS_NUM_FRAMES = total_frames // 20\n",
        "\n",
        "\n",
        "if frame_height > frame_width:\n",
        "  out_frame_height = 160\n",
        "  out_frame_width = 90\n",
        "\n",
        "else:\n",
        "  out_frame_height = 90\n",
        "  out_frame_width = 160\n",
        "\n",
        "out_frame_height = frame_height//1\n",
        "\n",
        "out_frame_width = frame_width//1\n",
        "\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        ######## some old code ############\n",
        "        # output_path = prefix + 'video_downsampled.mp4'\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        # out = cv2.VideoWriter(output_path, fourcc, fps, (out_frame_width , out_frame_height ))\n",
        "\n",
        "        # Create output directory if it doesn't exist\n",
        "output_dir = prefix + 'short_videos/'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "frame_counter = 0\n",
        "short_video_counter = 1\n",
        "out0 = None\n",
        "out1 = None\n",
        "out = [out0, out1]\n",
        "frame_counter = 0\n",
        "short_videos = []\n",
        "main_out = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_counter += 1\n",
        "\n",
        "    if frame_counter == 1:\n",
        "        short_video_path = os.path.join(output_dir, f'video_downsampled_1.mp4')\n",
        "        out[main_out] = cv2.VideoWriter(short_video_path, fourcc, fps, (out_frame_width, out_frame_height))\n",
        "        short_videos.append(short_video_path)\n",
        "\n",
        "        #### I removed this part ######\n",
        "    # Process every COMPRESS_NUM_FRAMES frame\n",
        "    if frame_counter % COMPRESS_NUM_FRAMES == 0:\n",
        "      # Resize the frame to reduce the number of pixels\n",
        "      ##################################\n",
        "\n",
        "      resized_frame = cv2.resize(frame, (out_frame_width  , out_frame_height))\n",
        "\n",
        "      # Write the resized frame to the output video\n",
        "\n",
        "      out[main_out].write(resized_frame)\n",
        "      if out[1 - main_out]:\n",
        "        out[1 - main_out].write(resized_frame)\n",
        "\n",
        "      # Quit by pressing on 'q' key\n",
        "      if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "          break\n",
        "\n",
        "    # out0 and out1 should be overlapping in 50 frames\n",
        "    if frame_counter == FRAMES_OVERLAP:\n",
        "      short_video_path = os.path.join(output_dir, f'video_downsampled_{short_video_counter+1}.mp4')\n",
        "      out[1- main_out] = cv2.VideoWriter(short_video_path, fourcc, fps, (out_frame_width, out_frame_height))\n",
        "      short_videos.append(short_video_path)\n",
        "\n",
        "    # If the frame counter reaches the desired number of frames per short video, release the current short video writer\n",
        "    if frame_counter == FRAMES_PER_SHORT_VIDEO:\n",
        "        out[main_out].release()\n",
        "        short_video_counter += 1\n",
        "        frame_counter = FRAMES_OVERLAP-1\n",
        "        main_out = 1 - main_out\n",
        "\n",
        "# Release everything when done\n",
        "cap.release()\n",
        "if out[main_out]:\n",
        "  out[main_out].release()\n",
        "if out[1-main_out]:\n",
        "  out[1-main_out].release()\n",
        "cv2.destroyAllWindows()\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f\"Total time taken: {total_time} seconds\", COMPRESS_NUM_FRAMES, total_frames, frame_width, frame_height)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4waAE0WwIcj",
        "outputId": "f3d653d7-d5f9-4af7-d449-7f6ffd90a13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time taken: 34.889177083969116 seconds 2 729 1080 1920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###### HELPER - no real code ##########\n",
        "video_path = prefix + 'video.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print(total_frames, out_frame_width, out_frame_height)\n",
        "short_videos"
      ],
      "metadata": {
        "id": "EN_MadUJMssV",
        "outputId": "8f07bd94-c083-4451-a5c2-a05de23c9c4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "729 1080 1920\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/short_videos/video_downsampled_1.mp4',\n",
              " '/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/short_videos/video_downsampled_2.mp4',\n",
              " '/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/short_videos/video_downsampled_3.mp4',\n",
              " '/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/short_videos/video_downsampled_4.mp4',\n",
              " '/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/short_videos/video_downsampled_5.mp4',\n",
              " '/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/short_videos/video_downsampled_6.mp4',\n",
              " '/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/short_videos/video_downsampled_7.mp4',\n",
              " '/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/short_videos/video_downsampled_8.mp4']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do mediaPipe on small videos"
      ],
      "metadata": {
        "id": "9hz5ySJyP7TS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########### MediaPipe short videos ################\n",
        "\n",
        "mp_holistic = mp.solutions.holistic\n",
        "i = 1\n",
        "for video_path in short_videos:\n",
        "  start_time = time.time()\n",
        "  total_saving_time = 0\n",
        "  total_net_time = 0\n",
        "\n",
        "\n",
        "  # Replace with your video file path\n",
        "  video_path = prefix +\"short_videos/\" f\"video_downsampled_{i}.mp4\"\n",
        "\n",
        "  # Create an empty list to store landmark data\n",
        "  data_list = []\n",
        "\n",
        "  with mp_holistic.Holistic(\n",
        "      model_complexity=0) as holistic:\n",
        "\n",
        "      # Open the video capture\n",
        "      cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "      # Process each video frame\n",
        "      while cap.isOpened():\n",
        "          success, image = cap.read()\n",
        "          if not success:\n",
        "              break\n",
        "\n",
        "          # Convert BGR to RGB for MediaPipe compatibility\n",
        "          # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "          # Process the image with MediaPipe Holistic\n",
        "          total_net_time_start = time.time()\n",
        "          results = holistic.process(image)\n",
        "          total_net_time_end = time.time()\n",
        "          print(f\"time taken to net: {total_net_time_end-total_net_time_start} seconds\")\n",
        "\n",
        "          total_net_time = total_net_time + (total_net_time_end-total_net_time_start)\n",
        "\n",
        "          only_net_start_save_time = time.time()\n",
        "\n",
        "          # Extract the selected landmarks and their coordinates\n",
        "          landmark_data = []\n",
        "          for column in selected_columns:\n",
        "              splitted = column.split('_')\n",
        "              if len(splitted) == 3:\n",
        "                coordinate, category, landmark = splitted\n",
        "              else:\n",
        "                coordinate = splitted[0][0]\n",
        "                category = splitted[1]  + \"_\"+ splitted[2]\n",
        "                landmark = splitted[3]\n",
        "\n",
        "              if category == 'pose' and results.pose_landmarks :\n",
        "                  tmp = getattr(results.pose_landmarks.landmark[int(landmark)],coordinate, None)\n",
        "              elif category == 'face' and results.face_landmarks:\n",
        "                  tmp = getattr(results.face_landmarks.landmark[int(landmark)], coordinate, None)\n",
        "              elif category == 'left_hand' and results.left_hand_landmarks:\n",
        "                  tmp= getattr(results.left_hand_landmarks.landmark[int(landmark)], coordinate, None)\n",
        "              elif category == 'right_hand' and results.right_hand_landmarks:\n",
        "                  tmp = getattr(results.right_hand_landmarks.landmark[int(landmark)], coordinate, None)\n",
        "\n",
        "              landmark_data.append( np.float32(tmp))\n",
        "\n",
        "          # Append landmark data for this frame to the list\n",
        "          data_list.append(landmark_data)\n",
        "\n",
        "          only_net_end_save_time = time.time()\n",
        "          total_saving_time = total_saving_time + (only_net_end_save_time - only_net_start_save_time)\n",
        "\n",
        "      # Release resources\n",
        "      cap.release()\n",
        "      cv2.destroyAllWindows()\n",
        "  # Create a DataFrame from the data list\n",
        "  df = pd.DataFrame(data_list, columns=selected_columns)\n",
        "\n",
        "  # Save the DataFrame as a Parquet file\n",
        "  df.to_parquet(prefix+f\"output_{i}.parquet\", index=False)\n",
        "\n",
        "  print(f\"Landmark data saved to output_{i}.parquet\")\n",
        "  end_time = time.time()\n",
        "  total_time = end_time - start_time\n",
        "  print(f\"Total time taken: {total_time} seconds\")\n",
        "\n",
        "  print(f\"time taken without saving: {total_time - total_saving_time} seconds\")\n",
        "\n",
        "  print(f\"time taken to net: {total_net_time} seconds\")\n",
        "  total_net_time = 0\n",
        "  i+=1"
      ],
      "metadata": {
        "id": "KxhwkIka7plT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "28940534-30b7-43ca-8e62-62e49e44eb78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time taken to net: 0.25911664962768555 seconds\n",
            "time taken to net: 0.10303020477294922 seconds\n",
            "time taken to net: 0.10482072830200195 seconds\n",
            "time taken to net: 0.10293817520141602 seconds\n",
            "time taken to net: 0.10558938980102539 seconds\n",
            "time taken to net: 0.10262012481689453 seconds\n",
            "time taken to net: 0.09709048271179199 seconds\n",
            "time taken to net: 0.09395074844360352 seconds\n",
            "time taken to net: 0.10801076889038086 seconds\n",
            "time taken to net: 0.11084794998168945 seconds\n",
            "time taken to net: 0.10385394096374512 seconds\n",
            "time taken to net: 0.1066129207611084 seconds\n",
            "time taken to net: 0.13778257369995117 seconds\n",
            "time taken to net: 0.16210293769836426 seconds\n",
            "time taken to net: 0.15053415298461914 seconds\n",
            "time taken to net: 0.17131996154785156 seconds\n",
            "time taken to net: 0.1724386215209961 seconds\n",
            "time taken to net: 0.13556814193725586 seconds\n",
            "time taken to net: 0.1568915843963623 seconds\n",
            "time taken to net: 0.1564655303955078 seconds\n",
            "time taken to net: 0.1423780918121338 seconds\n",
            "time taken to net: 0.1491990089416504 seconds\n",
            "time taken to net: 0.14655447006225586 seconds\n",
            "time taken to net: 0.15064287185668945 seconds\n",
            "time taken to net: 0.15800094604492188 seconds\n",
            "time taken to net: 0.1630845069885254 seconds\n",
            "time taken to net: 0.1658332347869873 seconds\n",
            "time taken to net: 0.14255094528198242 seconds\n",
            "time taken to net: 0.16376900672912598 seconds\n",
            "time taken to net: 0.15568184852600098 seconds\n",
            "time taken to net: 0.15102910995483398 seconds\n",
            "time taken to net: 0.14968466758728027 seconds\n",
            "time taken to net: 0.1714465618133545 seconds\n",
            "time taken to net: 0.14555144309997559 seconds\n",
            "time taken to net: 0.14801549911499023 seconds\n",
            "time taken to net: 0.14274001121520996 seconds\n",
            "time taken to net: 0.1664109230041504 seconds\n",
            "time taken to net: 0.1314256191253662 seconds\n",
            "time taken to net: 0.09750580787658691 seconds\n",
            "time taken to net: 0.09363460540771484 seconds\n",
            "time taken to net: 0.5741896629333496 seconds\n",
            "time taken to net: 0.12128376960754395 seconds\n",
            "time taken to net: 0.10509371757507324 seconds\n",
            "time taken to net: 0.09705662727355957 seconds\n",
            "time taken to net: 0.09337568283081055 seconds\n",
            "time taken to net: 0.09532761573791504 seconds\n",
            "time taken to net: 0.1067354679107666 seconds\n",
            "time taken to net: 0.10010290145874023 seconds\n",
            "time taken to net: 0.0955209732055664 seconds\n",
            "time taken to net: 0.0982675552368164 seconds\n",
            "time taken to net: 0.09518980979919434 seconds\n",
            "time taken to net: 0.11820220947265625 seconds\n",
            "time taken to net: 0.1001131534576416 seconds\n",
            "time taken to net: 0.0946035385131836 seconds\n",
            "time taken to net: 0.09418129920959473 seconds\n",
            "time taken to net: 0.10311698913574219 seconds\n",
            "time taken to net: 0.09895825386047363 seconds\n",
            "time taken to net: 0.09742879867553711 seconds\n",
            "time taken to net: 0.09372925758361816 seconds\n",
            "time taken to net: 0.09841322898864746 seconds\n",
            "time taken to net: 0.09232592582702637 seconds\n",
            "time taken to net: 0.11582088470458984 seconds\n",
            "time taken to net: 0.09444952011108398 seconds\n",
            "time taken to net: 0.09287691116333008 seconds\n",
            "time taken to net: 0.09048581123352051 seconds\n",
            "time taken to net: 0.09270620346069336 seconds\n",
            "time taken to net: 0.11474370956420898 seconds\n",
            "time taken to net: 0.09101295471191406 seconds\n",
            "time taken to net: 0.09090161323547363 seconds\n",
            "time taken to net: 0.09313726425170898 seconds\n",
            "time taken to net: 0.0968773365020752 seconds\n",
            "time taken to net: 0.11230206489562988 seconds\n",
            "time taken to net: 0.10190105438232422 seconds\n",
            "time taken to net: 0.11237716674804688 seconds\n",
            "time taken to net: 0.09673619270324707 seconds\n",
            "Landmark data saved to output_1.parquet\n",
            "Total time taken: 10.475743293762207 seconds\n",
            "time taken without saving: 10.384432315826416 seconds\n",
            "time taken to net: 9.54626989364624 seconds\n",
            "time taken to net: 0.2768537998199463 seconds\n",
            "time taken to net: 0.0990746021270752 seconds\n",
            "time taken to net: 0.09596991539001465 seconds\n",
            "time taken to net: 0.10106635093688965 seconds\n",
            "time taken to net: 0.09604334831237793 seconds\n",
            "time taken to net: 0.09441518783569336 seconds\n",
            "time taken to net: 0.09052395820617676 seconds\n",
            "time taken to net: 0.09664630889892578 seconds\n",
            "time taken to net: 0.09208798408508301 seconds\n",
            "time taken to net: 0.09416460990905762 seconds\n",
            "time taken to net: 0.10772585868835449 seconds\n",
            "time taken to net: 0.09781503677368164 seconds\n",
            "time taken to net: 0.09146761894226074 seconds\n",
            "time taken to net: 0.1006937026977539 seconds\n",
            "time taken to net: 0.09842729568481445 seconds\n",
            "time taken to net: 0.09575843811035156 seconds\n",
            "time taken to net: 0.09168267250061035 seconds\n",
            "time taken to net: 0.09844303131103516 seconds\n",
            "time taken to net: 0.09632277488708496 seconds\n",
            "time taken to net: 0.09499859809875488 seconds\n",
            "time taken to net: 0.10309958457946777 seconds\n",
            "time taken to net: 0.09450912475585938 seconds\n",
            "time taken to net: 0.09183669090270996 seconds\n",
            "time taken to net: 0.09796643257141113 seconds\n",
            "time taken to net: 0.09177732467651367 seconds\n",
            "time taken to net: 0.09490799903869629 seconds\n",
            "time taken to net: 0.09317588806152344 seconds\n",
            "time taken to net: 0.0969855785369873 seconds\n",
            "time taken to net: 0.09307169914245605 seconds\n",
            "time taken to net: 0.09402298927307129 seconds\n",
            "time taken to net: 0.11280035972595215 seconds\n",
            "time taken to net: 0.09022903442382812 seconds\n",
            "time taken to net: 0.09541130065917969 seconds\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-97b4b4054b1e>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m           \u001b[0;31m# Process the image with MediaPipe Holistic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m           \u001b[0mtotal_net_time_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m           \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mholistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m           \u001b[0mtotal_net_time_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"time taken to net: {total_net_time_end-total_net_time_start} seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mediapipe/python/solutions/holistic.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \"\"\"\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pytype: disable=attribute-error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlandmark\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pytype: disable=attribute-error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mediapipe/python/solution_base.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    362\u001b[0m         self._graph.add_packet_to_input_stream(\n\u001b[1;32m    363\u001b[0m             \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             packet=self._make_packet(input_stream_type,\n\u001b[0m\u001b[1;32m    365\u001b[0m                                      data).at(self._simulated_timestamp))\n\u001b[1;32m    366\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mediapipe/python/solution_base.py\u001b[0m in \u001b[0;36m_make_packet\u001b[0;34m(self, packet_data_type, data)\u001b[0m\n\u001b[1;32m    594\u001b[0m     if (packet_data_type == PacketDataType.IMAGE_FRAME or\n\u001b[1;32m    595\u001b[0m         packet_data_type == PacketDataType.IMAGE):\n\u001b[0;32m--> 596\u001b[0;31m       return getattr(packet_creator, 'create_' + packet_data_type.value)(\n\u001b[0m\u001b[1;32m    597\u001b[0m           data, image_format=image_frame.ImageFormat.SRGB)\n\u001b[1;32m    598\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mediapipe/python/packet_creator.py\u001b[0m in \u001b[0;36mcreate_image_frame\u001b[0;34m(data, image_format, copy)\u001b[0m\n\u001b[1;32m    145\u001b[0m             RuntimeWarning, 2)\n\u001b[1;32m    146\u001b[0m     \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     return _packet_creator._create_image_frame_from_pixel_data(\n\u001b[0m\u001b[1;32m    148\u001b[0m         image_format, data, copy)\n\u001b[1;32m    149\u001b[0m     \u001b[0;31m# pylint:enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/\"\n",
        "##### Mediapipe regualr #######\n",
        "mp_holistic = mp.solutions.holistic\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "  # Replace with your video file path\n",
        "video_path = prefix + \"video.mp4\"\n",
        "\n",
        "# Create an empty list to store landmark data\n",
        "data_list = []\n",
        "\n",
        "with mp_holistic.Holistic(\n",
        "    static_image_mode=True,\n",
        "    model_complexity=1,\n",
        "    enable_segmentation=False,\n",
        "    refine_face_landmarks=False) as holistic:\n",
        "\n",
        "    # Open the video capture\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Process each video frame\n",
        "    while cap.isOpened():\n",
        "        success, image = cap.read()\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # Convert BGR to RGB for MediaPipe compatibility\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Process the image with MediaPipe Holistic\n",
        "        results = holistic.process(image)\n",
        "\n",
        "        # Extract the selected landmarks and their coordinates\n",
        "        landmark_data = []\n",
        "        for column in selected_columns:\n",
        "            splitted = column.split('_')\n",
        "            if len(splitted) == 3:\n",
        "              coordinate, category, landmark = splitted\n",
        "            else:\n",
        "              coordinate = splitted[0][0]\n",
        "              category = splitted[1]  + \"_\"+ splitted[2]\n",
        "              landmark = splitted[3]\n",
        "\n",
        "            if category == 'pose' and results.pose_landmarks :\n",
        "                tmp = getattr(results.pose_landmarks.landmark[int(landmark)],coordinate, None)\n",
        "            elif category == 'face' and results.face_landmarks:\n",
        "                tmp = getattr(results.face_landmarks.landmark[int(landmark)], coordinate, None)\n",
        "            elif category == 'left_hand' and results.left_hand_landmarks:\n",
        "                tmp= getattr(results.left_hand_landmarks.landmark[int(landmark)], coordinate, None)\n",
        "            elif category == 'right_hand' and results.right_hand_landmarks:\n",
        "                tmp = getattr(results.right_hand_landmarks.landmark[int(landmark)], coordinate, None)\n",
        "\n",
        "            landmark_data.append( np.float32(tmp))\n",
        "\n",
        "        # Append landmark data for this frame to the list\n",
        "        data_list.append(landmark_data)\n",
        "\n",
        "    # Release resources\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Create a DataFrame from the data list\n",
        "df = pd.DataFrame(data_list, columns=selected_columns)\n",
        "\n",
        "# Save the DataFrame as a Parquet file\n",
        "df.to_parquet(prefix+f\"output.parquet\", index=False)\n",
        "\n",
        "print(f\"Landmark data saved to output.parquet\")\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f\"Total time taken: {total_time} seconds\")\n"
      ],
      "metadata": {
        "id": "p-kKGaPPPK4q",
        "outputId": "ae995daa-17db-44ca-a6f5-b4bb1dd96105",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Landmark data saved to output.parquet\n",
            "Total time taken: 111.2529149055481 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "read parquet"
      ],
      "metadata": {
        "id": "1e3Xc7kv62dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet(prefix+'output.parquet')\n",
        "row_count = df.shape[0]\n",
        "print (\"Num of rows in file =\", row_count)"
      ],
      "metadata": {
        "id": "Dhd0Svuo62HO",
        "outputId": "d11d4fc2-3b16-46b8-d7ca-a6847a55a68a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of rows in file = 712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "convert parquet to csv"
      ],
      "metadata": {
        "id": "apFXvW1Xz9yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.to_csv(prefix+'output.csv')\n"
      ],
      "metadata": {
        "id": "71TS1uZCz9Hi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f24e833-9258-46fa-b7f3-4d7bdd47c5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of rows in file = 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Frames per word after compression\n",
        "\n",
        "hi_my_name_is: 56/4 = 14\n",
        "\n",
        "Ilay_Chen: 39/2 = 19.5\n",
        "\n",
        "hello_Raizel: 20/1 = 20\n",
        "\n",
        "Raizel: 33/1 = 33"
      ],
      "metadata": {
        "id": "Lj7w0aUF7hSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ASL net\n",
        "### added here cause coalb is being difficult"
      ],
      "metadata": {
        "id": "BjpBv75YK6pX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflite_runtime"
      ],
      "metadata": {
        "id": "NBihBhr2LRH_",
        "outputId": "6dbc6cf6-15b0-4230-b01f-b71ad66eaf14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tflite_runtime\n",
            "  Downloading tflite_runtime-2.14.0-cp310-cp310-manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.10/dist-packages (from tflite_runtime) (1.25.2)\n",
            "Installing collected packages: tflite_runtime\n",
            "Successfully installed tflite_runtime-2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tflite_runtime.interpreter as tflite\n",
        "import json\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "_EY09uKbLLVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns = [\"x_face_0\", \"x_face_61\", \"x_face_185\", \"x_face_40\", \"x_face_39\", \"x_face_37\", \"x_face_267\", \"x_face_269\", \"x_face_270\", \"x_face_409\", \"x_face_291\", \"x_face_146\", \"x_face_91\", \"x_face_181\", \"x_face_84\", \"x_face_17\", \"x_face_314\", \"x_face_405\", \"x_face_321\", \"x_face_375\", \"x_face_78\", \"x_face_191\", \"x_face_80\", \"x_face_81\", \"x_face_82\", \"x_face_13\", \"x_face_312\", \"x_face_311\", \"x_face_310\", \"x_face_415\", \"x_face_95\", \"x_face_88\", \"x_face_178\", \"x_face_87\", \"x_face_14\", \"x_face_317\", \"x_face_402\", \"x_face_318\", \"x_face_324\", \"x_face_308\", \"x_left_hand_0\", \"x_left_hand_1\", \"x_left_hand_2\", \"x_left_hand_3\", \"x_left_hand_4\", \"x_left_hand_5\", \"x_left_hand_6\", \"x_left_hand_7\", \"x_left_hand_8\", \"x_left_hand_9\", \"x_left_hand_10\", \"x_left_hand_11\", \"x_left_hand_12\", \"x_left_hand_13\", \"x_left_hand_14\", \"x_left_hand_15\", \"x_left_hand_16\", \"x_left_hand_17\", \"x_left_hand_18\", \"x_left_hand_19\", \"x_left_hand_20\", \"x_right_hand_0\", \"x_right_hand_1\", \"x_right_hand_2\", \"x_right_hand_3\", \"x_right_hand_4\", \"x_right_hand_5\", \"x_right_hand_6\", \"x_right_hand_7\", \"x_right_hand_8\", \"x_right_hand_9\", \"x_right_hand_10\", \"x_right_hand_11\", \"x_right_hand_12\", \"x_right_hand_13\", \"x_right_hand_14\", \"x_right_hand_15\", \"x_right_hand_16\", \"x_right_hand_17\", \"x_right_hand_18\", \"x_right_hand_19\", \"x_right_hand_20\", \"x_face_1\", \"x_face_2\", \"x_face_98\", \"x_face_327\", \"x_face_33\", \"x_face_7\", \"x_face_163\", \"x_face_144\", \"x_face_145\", \"x_face_153\", \"x_face_154\", \"x_face_155\", \"x_face_133\", \"x_face_246\", \"x_face_161\", \"x_face_160\", \"x_face_159\", \"x_face_158\", \"x_face_157\", \"x_face_173\", \"x_face_263\", \"x_face_249\", \"x_face_390\", \"x_face_373\", \"x_face_374\", \"x_face_380\", \"x_face_381\", \"x_face_382\", \"x_face_362\", \"x_face_466\", \"x_face_388\", \"x_face_387\", \"x_face_386\", \"x_face_385\", \"x_face_384\", \"x_face_398\", \"x_pose_12\", \"x_pose_14\", \"x_pose_16\", \"x_pose_18\", \"x_pose_20\", \"x_pose_22\", \"x_pose_11\", \"x_pose_13\", \"x_pose_15\", \"x_pose_17\", \"x_pose_19\", \"x_pose_21\", \"y_face_0\", \"y_face_61\", \"y_face_185\", \"y_face_40\", \"y_face_39\", \"y_face_37\", \"y_face_267\", \"y_face_269\", \"y_face_270\", \"y_face_409\", \"y_face_291\", \"y_face_146\", \"y_face_91\", \"y_face_181\", \"y_face_84\", \"y_face_17\", \"y_face_314\", \"y_face_405\", \"y_face_321\", \"y_face_375\", \"y_face_78\", \"y_face_191\", \"y_face_80\", \"y_face_81\", \"y_face_82\", \"y_face_13\", \"y_face_312\", \"y_face_311\", \"y_face_310\", \"y_face_415\", \"y_face_95\", \"y_face_88\", \"y_face_178\", \"y_face_87\", \"y_face_14\", \"y_face_317\", \"y_face_402\", \"y_face_318\", \"y_face_324\", \"y_face_308\", \"y_left_hand_0\", \"y_left_hand_1\", \"y_left_hand_2\", \"y_left_hand_3\", \"y_left_hand_4\", \"y_left_hand_5\", \"y_left_hand_6\", \"y_left_hand_7\", \"y_left_hand_8\", \"y_left_hand_9\", \"y_left_hand_10\", \"y_left_hand_11\", \"y_left_hand_12\", \"y_left_hand_13\", \"y_left_hand_14\", \"y_left_hand_15\", \"y_left_hand_16\", \"y_left_hand_17\", \"y_left_hand_18\", \"y_left_hand_19\", \"y_left_hand_20\", \"y_right_hand_0\", \"y_right_hand_1\", \"y_right_hand_2\", \"y_right_hand_3\", \"y_right_hand_4\", \"y_right_hand_5\", \"y_right_hand_6\", \"y_right_hand_7\", \"y_right_hand_8\", \"y_right_hand_9\", \"y_right_hand_10\", \"y_right_hand_11\", \"y_right_hand_12\", \"y_right_hand_13\", \"y_right_hand_14\", \"y_right_hand_15\", \"y_right_hand_16\", \"y_right_hand_17\", \"y_right_hand_18\", \"y_right_hand_19\", \"y_right_hand_20\", \"y_face_1\", \"y_face_2\", \"y_face_98\", \"y_face_327\", \"y_face_33\", \"y_face_7\", \"y_face_163\", \"y_face_144\", \"y_face_145\", \"y_face_153\", \"y_face_154\", \"y_face_155\", \"y_face_133\", \"y_face_246\", \"y_face_161\", \"y_face_160\", \"y_face_159\", \"y_face_158\", \"y_face_157\", \"y_face_173\", \"y_face_263\", \"y_face_249\", \"y_face_390\", \"y_face_373\", \"y_face_374\", \"y_face_380\", \"y_face_381\", \"y_face_382\", \"y_face_362\", \"y_face_466\", \"y_face_388\", \"y_face_387\", \"y_face_386\", \"y_face_385\", \"y_face_384\", \"y_face_398\", \"y_pose_12\", \"y_pose_14\", \"y_pose_16\", \"y_pose_18\", \"y_pose_20\", \"y_pose_22\", \"y_pose_11\", \"y_pose_13\", \"y_pose_15\", \"y_pose_17\", \"y_pose_19\", \"y_pose_21\", \"z_face_0\", \"z_face_61\", \"z_face_185\", \"z_face_40\", \"z_face_39\", \"z_face_37\", \"z_face_267\", \"z_face_269\", \"z_face_270\", \"z_face_409\", \"z_face_291\", \"z_face_146\", \"z_face_91\", \"z_face_181\", \"z_face_84\", \"z_face_17\", \"z_face_314\", \"z_face_405\", \"z_face_321\", \"z_face_375\", \"z_face_78\", \"z_face_191\", \"z_face_80\", \"z_face_81\", \"z_face_82\", \"z_face_13\", \"z_face_312\", \"z_face_311\", \"z_face_310\", \"z_face_415\", \"z_face_95\", \"z_face_88\", \"z_face_178\", \"z_face_87\", \"z_face_14\", \"z_face_317\", \"z_face_402\", \"z_face_318\", \"z_face_324\", \"z_face_308\", \"z_left_hand_0\", \"z_left_hand_1\", \"z_left_hand_2\", \"z_left_hand_3\", \"z_left_hand_4\", \"z_left_hand_5\", \"z_left_hand_6\", \"z_left_hand_7\", \"z_left_hand_8\", \"z_left_hand_9\", \"z_left_hand_10\", \"z_left_hand_11\", \"z_left_hand_12\", \"z_left_hand_13\", \"z_left_hand_14\", \"z_left_hand_15\", \"z_left_hand_16\", \"z_left_hand_17\", \"z_left_hand_18\", \"z_left_hand_19\", \"z_left_hand_20\", \"z_right_hand_0\", \"z_right_hand_1\", \"z_right_hand_2\", \"z_right_hand_3\", \"z_right_hand_4\", \"z_right_hand_5\", \"z_right_hand_6\", \"z_right_hand_7\", \"z_right_hand_8\", \"z_right_hand_9\", \"z_right_hand_10\", \"z_right_hand_11\", \"z_right_hand_12\", \"z_right_hand_13\", \"z_right_hand_14\", \"z_right_hand_15\", \"z_right_hand_16\", \"z_right_hand_17\", \"z_right_hand_18\", \"z_right_hand_19\", \"z_right_hand_20\", \"z_face_1\", \"z_face_2\", \"z_face_98\", \"z_face_327\", \"z_face_33\", \"z_face_7\", \"z_face_163\", \"z_face_144\", \"z_face_145\", \"z_face_153\", \"z_face_154\", \"z_face_155\", \"z_face_133\", \"z_face_246\", \"z_face_161\", \"z_face_160\", \"z_face_159\", \"z_face_158\", \"z_face_157\", \"z_face_173\", \"z_face_263\", \"z_face_249\", \"z_face_390\", \"z_face_373\", \"z_face_374\", \"z_face_380\", \"z_face_381\", \"z_face_382\", \"z_face_362\", \"z_face_466\", \"z_face_388\", \"z_face_387\", \"z_face_386\", \"z_face_385\", \"z_face_384\", \"z_face_398\", \"z_pose_12\", \"z_pose_14\", \"z_pose_16\", \"z_pose_18\", \"z_pose_20\", \"z_pose_22\", \"z_pose_11\", \"z_pose_13\", \"z_pose_15\", \"z_pose_17\", \"z_pose_19\", \"z_pose_21\"]"
      ],
      "metadata": {
        "id": "ZK45l-aULJK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_relevant_data_subset(pq_path):\n",
        "    return pd.read_parquet(pq_path, columns=selected_columns)"
      ],
      "metadata": {
        "id": "e92mywKeLE3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########### Detector net short videos ##########\n",
        "i = 1\n",
        "prefix = f'/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/output_{i}.parquet'\n",
        "while os.path.exists(prefix):\n",
        "  start_time = time.time()\n",
        "  frames = load_relevant_data_subset(prefix)\n",
        "  interpreter = tflite.Interpreter(\"/content/gdrive/MyDrive/ASL_fingerspelling_project/models/model.tflite\")\n",
        "\n",
        "  REQUIRED_SIGNATURE = \"serving_default\"\n",
        "  REQUIRED_OUTPUT = \"outputs\"\n",
        "\n",
        "  with open (\"/content/gdrive/MyDrive/ASL_fingerspelling_project/models/character_to_prediction_index.json\", \"r\") as f:\n",
        "      character_map = json.load(f)\n",
        "  rev_character_map = {j:i for i,j in character_map.items()}\n",
        "\n",
        "  found_signatures = list(interpreter.get_signature_list().keys())\n",
        "\n",
        "  if REQUIRED_SIGNATURE not in found_signatures:\n",
        "      raise KernelEvalException('Required input signature not found.')\n",
        "\n",
        "  prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
        "\n",
        "  output = prediction_fn(inputs=frames)\n",
        "  # output = prediction_fn(inputs=cuted_frames)\n",
        "\n",
        "  prediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output[REQUIRED_OUTPUT], axis=1)])\n",
        "  print (prediction_str)\n",
        "  end_time = time.time()\n",
        "  total_time = end_time - start_time\n",
        "  print(f\"Total time taken: {total_time} seconds\")\n",
        "  i += 1\n",
        "  prefix = f'/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/output_{i}.parquet'"
      ],
      "metadata": {
        "id": "KiWcgmbBK6Cs",
        "outputId": "b4d2f39d-c985-4ba5-efe2-1b62d370febe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tisiaca\n",
            "Total time taken: 3.2726755142211914 seconds\n",
            "sisa video\n",
            "Total time taken: 3.0265185832977295 seconds\n",
            "100-010-4142\n",
            "Total time taken: 3.060882568359375 seconds\n",
            "son street south this month\n",
            "Total time taken: 3.5280752182006836 seconds\n",
            "the anny\n",
            "Total time taken: 4.5022618770599365 seconds\n",
            "jonny woods\n",
            "Total time taken: 3.227696418762207 seconds\n",
            "ars\n",
            "Total time taken: 3.2177321910858154 seconds\n",
            "www.services.com/states-san\n",
            "Total time taken: 3.63506817817688 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######## setector net regular ########\n",
        "prefix = f'/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/output.parquet'\n",
        "\n",
        "start_time = time.time()\n",
        "frames = load_relevant_data_subset(prefix)\n",
        "interpreter = tflite.Interpreter(\"/content/gdrive/MyDrive/ASL_fingerspelling_project/models/model.tflite\")\n",
        "\n",
        "REQUIRED_SIGNATURE = \"serving_default\"\n",
        "REQUIRED_OUTPUT = \"outputs\"\n",
        "\n",
        "with open (\"/content/gdrive/MyDrive/ASL_fingerspelling_project/models/character_to_prediction_index.json\", \"r\") as f:\n",
        "    character_map = json.load(f)\n",
        "rev_character_map = {j:i for i,j in character_map.items()}\n",
        "\n",
        "found_signatures = list(interpreter.get_signature_list().keys())\n",
        "\n",
        "if REQUIRED_SIGNATURE not in found_signatures:\n",
        "    raise KernelEvalException('Required input signature not found.')\n",
        "\n",
        "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
        "\n",
        "output = prediction_fn(inputs=frames)\n",
        "# output = prediction_fn(inputs=cuted_frames)\n",
        "\n",
        "prediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output[REQUIRED_OUTPUT], axis=1)])\n",
        "print (prediction_str)\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f\"Total time taken: {total_time} seconds\")"
      ],
      "metadata": {
        "id": "_vBPv7MjSX-q",
        "outputId": "8851398d-331b-4e90-9ce5-aad0ad1a7202",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tisisa video with many words\n",
            "Total time taken: 4.551240921020508 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***one pipeline - run all frame by frame.***"
      ],
      "metadata": {
        "id": "Zco-t1z3PxJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process"
      ],
      "metadata": {
        "id": "-47jKIhNg8eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_words_prediction(data_list, prediction_fn):\n",
        "          # Create a DataFrame from the data list\n",
        "          frames = pd.DataFrame(data_list, columns=selected_columns)\n",
        "          output = prediction_fn(inputs=frames)\n",
        "          # now predict\n",
        "          prediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output[REQUIRED_OUTPUT], axis=1)])\n",
        "          print (prediction_str)\n",
        "\n",
        "          end_time = time.time()\n",
        "          total_time = end_time - start_time\n",
        "          print(f\"Total time taken so far: {total_time} seconds\")\n",
        "\n",
        "          # Get the current frame number\n",
        "          current_frame_number = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
        "\n",
        "          # Calculate the time in seconds\n",
        "          time_in_seconds = current_frame_number / fps\n",
        "\n",
        "          print(f\"Time elapsed at video so far: {time_in_seconds} seconds\")"
      ],
      "metadata": {
        "id": "4moVSTFtg-Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets simulate the input video\n",
        "prefix = \"/home/ilaych/Projects/asl_playground/\"\n",
        "##### Mediapipe regualr #######\n",
        "mp_holistic = mp.solutions.holistic\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "# Replace with your video file path\n",
        "video_path = prefix + \"video.mp4\"\n",
        "count = 1\n",
        "\n",
        "# Some important paramenters\n",
        "COMPRESS_NUM_FRAMES = 2    # take one frame from each COMPRESS_NUM_FRAMES\n",
        "FRAMES_PER_SHORT_VIDEO = 100\n",
        "FRAMES_OVERLAP = 25\n",
        "# if total_frames // COMPRESS_NUM_FRAMES < 15:   # min num of frames for detection is 15\n",
        "#   COMPRESS_NUM_FRAMES = total_frames // 20\n",
        "\n",
        "# Lets load the detection net\n",
        "interpreter = tflite.Interpreter(\"/home/ilaych/Projects/asl_playground/model.tflite\")\n",
        "\n",
        "REQUIRED_SIGNATURE = \"serving_default\"\n",
        "REQUIRED_OUTPUT = \"outputs\"\n",
        "\n",
        "with open (\"/home/ilaych/Projects/asl_playground/character_to_prediction_index.json\", \"r\") as f:\n",
        "    character_map = json.load(f)\n",
        "rev_character_map = {j:i for i,j in character_map.items()}\n",
        "\n",
        "found_signatures = list(interpreter.get_signature_list().keys())\n",
        "\n",
        "if REQUIRED_SIGNATURE not in found_signatures:\n",
        "    raise KernelEvalException('Required input signature not found.')\n",
        "\n",
        "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
        "\n",
        "\n",
        "# Create an empty list to store landmark data\n",
        "data_list = []\n",
        "\n",
        "skip_image = False\n",
        "\n",
        "with mp_holistic.Holistic(\n",
        "    model_complexity=1) as holistic:\n",
        "\n",
        "    # Open the video capture\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Get frames per second (fps)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    print(f\"The frames per second of the video is: {fps}\")\n",
        "\n",
        "    # Process each video frame\n",
        "    while cap.isOpened():\n",
        "        success, image = cap.read()\n",
        "\n",
        "        # read only every second frame\n",
        "        if skip_image:\n",
        "          skip_image = False\n",
        "          continue\n",
        "        if not skip_image:\n",
        "          skip_image = True\n",
        "\n",
        "        if not success:\n",
        "          if len(data_list) != 0:\n",
        "            print(\"call the net!!\")\n",
        "            # server1 = Process(target=run_words_prediction(data_list, prediction_fn))\n",
        "            server1 = Process(target=run_words_prediction, args=(data_list, prediction_fn))\n",
        "            server1.start()\n",
        "            server1.join()\n",
        "          break\n",
        "\n",
        "        # current_frame_number = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
        "        # print(f\"frames gone so far: {current_frame_number}/{total_frames} frames\")\n",
        "\n",
        "        # Convert BGR to RGB for MediaPipe compatibility\n",
        "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Process the image with MediaPipe Holistic\n",
        "        results = holistic.process(image)\n",
        "\n",
        "        # Extract the selected landmarks and their coordinates\n",
        "        landmark_data = []\n",
        "        for column in selected_columns:\n",
        "            splitted = column.split('_')\n",
        "            if len(splitted) == 3:\n",
        "              coordinate, category, landmark = splitted\n",
        "            else:\n",
        "              coordinate = splitted[0][0]\n",
        "              category = splitted[1]  + \"_\"+ splitted[2]\n",
        "              landmark = splitted[3]\n",
        "\n",
        "            if category == 'pose' and results.pose_landmarks :\n",
        "                tmp = getattr(results.pose_landmarks.landmark[int(landmark)],coordinate, None)\n",
        "            elif category == 'face' and results.face_landmarks:\n",
        "                tmp = getattr(results.face_landmarks.landmark[int(landmark)], coordinate, None)\n",
        "            elif category == 'left_hand' and results.left_hand_landmarks:\n",
        "                tmp= getattr(results.left_hand_landmarks.landmark[int(landmark)], coordinate, None)\n",
        "            elif category == 'right_hand' and results.right_hand_landmarks:\n",
        "                tmp = getattr(results.right_hand_landmarks.landmark[int(landmark)], coordinate, None)\n",
        "\n",
        "            landmark_data.append(np.float32(tmp))\n",
        "\n",
        "        # Append landmark data for this frame to the list\n",
        "        data_list.append(landmark_data)\n",
        "\n",
        "        if len(data_list) == (FRAMES_PER_SHORT_VIDEO+FRAMES_OVERLAP)*count:\n",
        "          print(\"call the net!!\")\n",
        "          # server1 = Process(target=run_words_prediction(data_list, prediction_fn))\n",
        "          server1 = Process(target=run_words_prediction, args=(data_list, prediction_fn))\n",
        "          server1.start()\n",
        "          count = count + 1\n",
        "\n",
        "          # remove unnessesery data (?) why not run prediction on all data?? mybe the same time?\n",
        "          # Remove the specified number of rows from the beginning of the list\n",
        "          # data_list = data_list[FRAMES_PER_SHORT_VIDEO:]\n",
        "\n",
        "\n",
        "    # Release resources\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Create a DataFrame from the data list\n",
        "df = pd.DataFrame(data_list, columns=selected_columns)\n",
        "\n",
        "# Save the DataFrame as a Parquet file\n",
        "df.to_parquet(prefix+f\"output.parquet\", index=False)\n",
        "\n",
        "print(f\"Landmark data saved to output.parquet\")\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f\"Total time taken: {total_time} seconds\")"
      ],
      "metadata": {
        "id": "IVdZgMnb05lU",
        "outputId": "76194584-a23d-469f-abe7-f406012d68c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The frames per second of the video is: 30.0\n",
            "call the net!!\n",
            "tisisa video\n",
            "Total time taken so far: 28.579086542129517 seconds\n",
            "Time elapsed at video so far: 8.3 seconds\n",
            "call the net!!\n",
            "100 withsma\n",
            "Total time taken so far: 48.97476649284363 seconds\n",
            "Time elapsed at video so far: 14.966666666666667 seconds\n",
            "call the net!!\n",
            "hamany woord\n",
            "Total time taken so far: 69.96485757827759 seconds\n",
            "Time elapsed at video so far: 21.633333333333333 seconds\n",
            "call the net!!\n",
            "Landmark data saved to output.parquet\n",
            "Total time taken: 72.23447132110596 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X_1lkOLEQoH1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}