{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raizelgestetner/ASL_fingerspelling/blob/main/photo2parquet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding some text"
      ],
      "metadata": {
        "id": "9hYwDhxklOrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enoyeVOVZsfu",
        "outputId": "d17b4f50-32ae-41b2-ee86-252d9d82c107"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yiIF3BGWj_YP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "023053f3-100b-4484-8010-0fcb496f965f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.5.26)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.25.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.9 sounddevice-0.4.6\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "import subprocess\n",
        "import time\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "-tcnkvm-kBaT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_holistic = mp.solutions.holistic"
      ],
      "metadata": {
        "id": "6OTRHQn2kKus"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns = [\"x_face_0\", \"x_face_61\", \"x_face_185\", \"x_face_40\", \"x_face_39\", \"x_face_37\", \"x_face_267\", \"x_face_269\", \"x_face_270\", \"x_face_409\", \"x_face_291\", \"x_face_146\", \"x_face_91\", \"x_face_181\", \"x_face_84\", \"x_face_17\", \"x_face_314\", \"x_face_405\", \"x_face_321\", \"x_face_375\", \"x_face_78\", \"x_face_191\", \"x_face_80\", \"x_face_81\", \"x_face_82\", \"x_face_13\", \"x_face_312\", \"x_face_311\", \"x_face_310\", \"x_face_415\", \"x_face_95\", \"x_face_88\", \"x_face_178\", \"x_face_87\", \"x_face_14\", \"x_face_317\", \"x_face_402\", \"x_face_318\", \"x_face_324\", \"x_face_308\", \"x_left_hand_0\", \"x_left_hand_1\", \"x_left_hand_2\", \"x_left_hand_3\", \"x_left_hand_4\", \"x_left_hand_5\", \"x_left_hand_6\", \"x_left_hand_7\", \"x_left_hand_8\", \"x_left_hand_9\", \"x_left_hand_10\", \"x_left_hand_11\", \"x_left_hand_12\", \"x_left_hand_13\", \"x_left_hand_14\", \"x_left_hand_15\", \"x_left_hand_16\", \"x_left_hand_17\", \"x_left_hand_18\", \"x_left_hand_19\", \"x_left_hand_20\", \"x_right_hand_0\", \"x_right_hand_1\", \"x_right_hand_2\", \"x_right_hand_3\", \"x_right_hand_4\", \"x_right_hand_5\", \"x_right_hand_6\", \"x_right_hand_7\", \"x_right_hand_8\", \"x_right_hand_9\", \"x_right_hand_10\", \"x_right_hand_11\", \"x_right_hand_12\", \"x_right_hand_13\", \"x_right_hand_14\", \"x_right_hand_15\", \"x_right_hand_16\", \"x_right_hand_17\", \"x_right_hand_18\", \"x_right_hand_19\", \"x_right_hand_20\", \"x_face_1\", \"x_face_2\", \"x_face_98\", \"x_face_327\", \"x_face_33\", \"x_face_7\", \"x_face_163\", \"x_face_144\", \"x_face_145\", \"x_face_153\", \"x_face_154\", \"x_face_155\", \"x_face_133\", \"x_face_246\", \"x_face_161\", \"x_face_160\", \"x_face_159\", \"x_face_158\", \"x_face_157\", \"x_face_173\", \"x_face_263\", \"x_face_249\", \"x_face_390\", \"x_face_373\", \"x_face_374\", \"x_face_380\", \"x_face_381\", \"x_face_382\", \"x_face_362\", \"x_face_466\", \"x_face_388\", \"x_face_387\", \"x_face_386\", \"x_face_385\", \"x_face_384\", \"x_face_398\", \"x_pose_12\", \"x_pose_14\", \"x_pose_16\", \"x_pose_18\", \"x_pose_20\", \"x_pose_22\", \"x_pose_11\", \"x_pose_13\", \"x_pose_15\", \"x_pose_17\", \"x_pose_19\", \"x_pose_21\", \"y_face_0\", \"y_face_61\", \"y_face_185\", \"y_face_40\", \"y_face_39\", \"y_face_37\", \"y_face_267\", \"y_face_269\", \"y_face_270\", \"y_face_409\", \"y_face_291\", \"y_face_146\", \"y_face_91\", \"y_face_181\", \"y_face_84\", \"y_face_17\", \"y_face_314\", \"y_face_405\", \"y_face_321\", \"y_face_375\", \"y_face_78\", \"y_face_191\", \"y_face_80\", \"y_face_81\", \"y_face_82\", \"y_face_13\", \"y_face_312\", \"y_face_311\", \"y_face_310\", \"y_face_415\", \"y_face_95\", \"y_face_88\", \"y_face_178\", \"y_face_87\", \"y_face_14\", \"y_face_317\", \"y_face_402\", \"y_face_318\", \"y_face_324\", \"y_face_308\", \"y_left_hand_0\", \"y_left_hand_1\", \"y_left_hand_2\", \"y_left_hand_3\", \"y_left_hand_4\", \"y_left_hand_5\", \"y_left_hand_6\", \"y_left_hand_7\", \"y_left_hand_8\", \"y_left_hand_9\", \"y_left_hand_10\", \"y_left_hand_11\", \"y_left_hand_12\", \"y_left_hand_13\", \"y_left_hand_14\", \"y_left_hand_15\", \"y_left_hand_16\", \"y_left_hand_17\", \"y_left_hand_18\", \"y_left_hand_19\", \"y_left_hand_20\", \"y_right_hand_0\", \"y_right_hand_1\", \"y_right_hand_2\", \"y_right_hand_3\", \"y_right_hand_4\", \"y_right_hand_5\", \"y_right_hand_6\", \"y_right_hand_7\", \"y_right_hand_8\", \"y_right_hand_9\", \"y_right_hand_10\", \"y_right_hand_11\", \"y_right_hand_12\", \"y_right_hand_13\", \"y_right_hand_14\", \"y_right_hand_15\", \"y_right_hand_16\", \"y_right_hand_17\", \"y_right_hand_18\", \"y_right_hand_19\", \"y_right_hand_20\", \"y_face_1\", \"y_face_2\", \"y_face_98\", \"y_face_327\", \"y_face_33\", \"y_face_7\", \"y_face_163\", \"y_face_144\", \"y_face_145\", \"y_face_153\", \"y_face_154\", \"y_face_155\", \"y_face_133\", \"y_face_246\", \"y_face_161\", \"y_face_160\", \"y_face_159\", \"y_face_158\", \"y_face_157\", \"y_face_173\", \"y_face_263\", \"y_face_249\", \"y_face_390\", \"y_face_373\", \"y_face_374\", \"y_face_380\", \"y_face_381\", \"y_face_382\", \"y_face_362\", \"y_face_466\", \"y_face_388\", \"y_face_387\", \"y_face_386\", \"y_face_385\", \"y_face_384\", \"y_face_398\", \"y_pose_12\", \"y_pose_14\", \"y_pose_16\", \"y_pose_18\", \"y_pose_20\", \"y_pose_22\", \"y_pose_11\", \"y_pose_13\", \"y_pose_15\", \"y_pose_17\", \"y_pose_19\", \"y_pose_21\", \"z_face_0\", \"z_face_61\", \"z_face_185\", \"z_face_40\", \"z_face_39\", \"z_face_37\", \"z_face_267\", \"z_face_269\", \"z_face_270\", \"z_face_409\", \"z_face_291\", \"z_face_146\", \"z_face_91\", \"z_face_181\", \"z_face_84\", \"z_face_17\", \"z_face_314\", \"z_face_405\", \"z_face_321\", \"z_face_375\", \"z_face_78\", \"z_face_191\", \"z_face_80\", \"z_face_81\", \"z_face_82\", \"z_face_13\", \"z_face_312\", \"z_face_311\", \"z_face_310\", \"z_face_415\", \"z_face_95\", \"z_face_88\", \"z_face_178\", \"z_face_87\", \"z_face_14\", \"z_face_317\", \"z_face_402\", \"z_face_318\", \"z_face_324\", \"z_face_308\", \"z_left_hand_0\", \"z_left_hand_1\", \"z_left_hand_2\", \"z_left_hand_3\", \"z_left_hand_4\", \"z_left_hand_5\", \"z_left_hand_6\", \"z_left_hand_7\", \"z_left_hand_8\", \"z_left_hand_9\", \"z_left_hand_10\", \"z_left_hand_11\", \"z_left_hand_12\", \"z_left_hand_13\", \"z_left_hand_14\", \"z_left_hand_15\", \"z_left_hand_16\", \"z_left_hand_17\", \"z_left_hand_18\", \"z_left_hand_19\", \"z_left_hand_20\", \"z_right_hand_0\", \"z_right_hand_1\", \"z_right_hand_2\", \"z_right_hand_3\", \"z_right_hand_4\", \"z_right_hand_5\", \"z_right_hand_6\", \"z_right_hand_7\", \"z_right_hand_8\", \"z_right_hand_9\", \"z_right_hand_10\", \"z_right_hand_11\", \"z_right_hand_12\", \"z_right_hand_13\", \"z_right_hand_14\", \"z_right_hand_15\", \"z_right_hand_16\", \"z_right_hand_17\", \"z_right_hand_18\", \"z_right_hand_19\", \"z_right_hand_20\", \"z_face_1\", \"z_face_2\", \"z_face_98\", \"z_face_327\", \"z_face_33\", \"z_face_7\", \"z_face_163\", \"z_face_144\", \"z_face_145\", \"z_face_153\", \"z_face_154\", \"z_face_155\", \"z_face_133\", \"z_face_246\", \"z_face_161\", \"z_face_160\", \"z_face_159\", \"z_face_158\", \"z_face_157\", \"z_face_173\", \"z_face_263\", \"z_face_249\", \"z_face_390\", \"z_face_373\", \"z_face_374\", \"z_face_380\", \"z_face_381\", \"z_face_382\", \"z_face_362\", \"z_face_466\", \"z_face_388\", \"z_face_387\", \"z_face_386\", \"z_face_385\", \"z_face_384\", \"z_face_398\", \"z_pose_12\", \"z_pose_14\", \"z_pose_16\", \"z_pose_18\", \"z_pose_20\", \"z_pose_22\", \"z_pose_11\", \"z_pose_13\", \"z_pose_15\", \"z_pose_17\", \"z_pose_19\", \"z_pose_21\"]"
      ],
      "metadata": {
        "id": "9ag867WC_PFJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/\""
      ],
      "metadata": {
        "id": "Jg6YpJhN5_n1"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compress video before runnign MediaPipe:\n",
        "reduce amount of frames and pixels"
      ],
      "metadata": {
        "id": "tnnI6Mt1oBoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "video_path = prefix + 'video.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "COMPRESS_NUM_FRAMES = 5    # take one frame from each COMPRESS_NUM_FRAMES\n",
        "COMPRESS_PIXELS = 15       # divide amount of pixels by COMPRESS_PIXELS\n",
        "FRAMES_PER_SHORT_VIDEO = 150\n",
        "if total_frames // COMPRESS_NUM_FRAMES < 15:   # min num of frames for detection is 15\n",
        "  COMPRESS_NUM_FRAMES = total_frames // 20\n",
        "\n",
        "\n",
        "if frame_height > frame_width:\n",
        "  out_frame_height = 160\n",
        "  out_frame_width = 90\n",
        "\n",
        "else:\n",
        "  out_frame_height = 90\n",
        "  out_frame_width = 160\n",
        "\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        ######## some old code ############\n",
        "        # output_path = prefix + 'video_downsampled.mp4'\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        # out = cv2.VideoWriter(output_path, fourcc, fps, (out_frame_width , out_frame_height ))\n",
        "\n",
        "        # Create output directory if it doesn't exist\n",
        "output_dir = prefix + 'short_videos/'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "frame_counter = 0\n",
        "short_video_counter = 1\n",
        "out0 = None\n",
        "out1 = None\n",
        "out = [out0, out1]\n",
        "frame_counter = 0\n",
        "short_videos = []\n",
        "main_out = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_counter += 1\n",
        "\n",
        "    if frame_counter == 1:\n",
        "        short_video_path = os.path.join(output_dir, f'video_downsampled_1.mp4')\n",
        "        out[main_out] = cv2.VideoWriter(short_video_path, fourcc, fps, (out_frame_width, out_frame_height))\n",
        "        short_videos.append(short_video_path)\n",
        "\n",
        "        #### I removed this part ######\n",
        "    # Process every COMPRESS_NUM_FRAMES frame\n",
        "    if frame_counter % COMPRESS_NUM_FRAMES == 0:\n",
        "      # Resize the frame to reduce the number of pixels\n",
        "      ##################################\n",
        "\n",
        "      resized_frame = cv2.resize(frame, (out_frame_width  , out_frame_height))\n",
        "\n",
        "      # Write the resized frame to the output video\n",
        "\n",
        "      out[main_out].write(resized_frame)\n",
        "      if out[1 - main_out]:\n",
        "        out[1 - main_out].write(resized_frame)\n",
        "\n",
        "      # Quit by pressing on 'q' key\n",
        "      if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "          break\n",
        "\n",
        "    # out0 and out1 should be overlapping in 50 frames\n",
        "    if frame_counter == 50:\n",
        "      short_video_path = os.path.join(output_dir, f'video_downsampled_{short_video_counter+1}.mp4')\n",
        "      out[1- main_out] = cv2.VideoWriter(short_video_path, fourcc, fps, (out_frame_width, out_frame_height))\n",
        "      short_videos.append(short_video_path)\n",
        "\n",
        "    # If the frame counter reaches the desired number of frames per short video, release the current short video writer\n",
        "    if frame_counter == FRAMES_PER_SHORT_VIDEO:\n",
        "        out[main_out].release()\n",
        "        short_video_counter += 1\n",
        "        frame_counter = 49\n",
        "        main_out = 1 - main_out\n",
        "\n",
        "# Release everything when done\n",
        "cap.release()\n",
        "if out[main_out]:\n",
        "  out[main_out].release()\n",
        "if out[1-main_out]:\n",
        "  out[1-main_out].release()\n",
        "cv2.destroyAllWindows()\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f\"Total time taken: {total_time} seconds\", COMPRESS_NUM_FRAMES, total_frames, frame_width, frame_height)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4waAE0WwIcj",
        "outputId": "70a1f84a-f12f-4f85-a96a-e228f6db13a9"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time taken: 16.617290496826172 seconds 5 729 1080 1920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###### HELPER - no real code ##########\n",
        "video_path = prefix + 'video.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print(total_frames, out_frame_width, out_frame_height)\n",
        "short_videos"
      ],
      "metadata": {
        "id": "EN_MadUJMssV",
        "outputId": "37e33aaa-6f08-4466-d9ad-738ff6495e22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "729 90 160\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/short_videos/video_downsampled_1.mp4',\n",
              " '/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/short_videos/video_downsampled_2.mp4',\n",
              " '/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/short_videos/video_downsampled_3.mp4',\n",
              " '/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/short_videos/video_downsampled_4.mp4',\n",
              " '/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/short_videos/video_downsampled_5.mp4',\n",
              " '/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/short_videos/video_downsampled_6.mp4',\n",
              " '/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/short_videos/video_downsampled_7.mp4',\n",
              " '/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/short_videos/video_downsampled_8.mp4']"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do mediaPipe on small videos"
      ],
      "metadata": {
        "id": "9hz5ySJyP7TS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########### MediaPipe short videos ################\n",
        "\n",
        "mp_holistic = mp.solutions.holistic\n",
        "i = 1\n",
        "for video_path in short_videos:\n",
        "  start_time = time.time()\n",
        "\n",
        "\n",
        "  # Replace with your video file path\n",
        "  video_path = prefix +\"short_videos/\" f\"video_downsampled_{i}.mp4\"\n",
        "\n",
        "  # Create an empty list to store landmark data\n",
        "  data_list = []\n",
        "\n",
        "  with mp_holistic.Holistic(\n",
        "      static_image_mode=True,\n",
        "      model_complexity=2,\n",
        "      enable_segmentation=True,\n",
        "      refine_face_landmarks=True) as holistic:\n",
        "\n",
        "      # Open the video capture\n",
        "      cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "      # Process each video frame\n",
        "      while cap.isOpened():\n",
        "          success, image = cap.read()\n",
        "          if not success:\n",
        "              break\n",
        "\n",
        "          # Convert BGR to RGB for MediaPipe compatibility\n",
        "          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "          # Process the image with MediaPipe Holistic\n",
        "          results = holistic.process(image)\n",
        "\n",
        "          # Extract the selected landmarks and their coordinates\n",
        "          landmark_data = []\n",
        "          for column in selected_columns:\n",
        "              splitted = column.split('_')\n",
        "              if len(splitted) == 3:\n",
        "                coordinate, category, landmark = splitted\n",
        "              else:\n",
        "                coordinate = splitted[0][0]\n",
        "                category = splitted[1]  + \"_\"+ splitted[2]\n",
        "                landmark = splitted[3]\n",
        "\n",
        "              if category == 'pose' and results.pose_landmarks :\n",
        "                  tmp = getattr(results.pose_landmarks.landmark[int(landmark)],coordinate, None)\n",
        "              elif category == 'face' and results.face_landmarks:\n",
        "                  tmp = getattr(results.face_landmarks.landmark[int(landmark)], coordinate, None)\n",
        "              elif category == 'left_hand' and results.left_hand_landmarks:\n",
        "                  tmp= getattr(results.left_hand_landmarks.landmark[int(landmark)], coordinate, None)\n",
        "              elif category == 'right_hand' and results.right_hand_landmarks:\n",
        "                  tmp = getattr(results.right_hand_landmarks.landmark[int(landmark)], coordinate, None)\n",
        "\n",
        "              landmark_data.append( np.float32(tmp))\n",
        "\n",
        "          # Append landmark data for this frame to the list\n",
        "          data_list.append(landmark_data)\n",
        "\n",
        "      # Release resources\n",
        "      cap.release()\n",
        "      cv2.destroyAllWindows()\n",
        "\n",
        "  # Create a DataFrame from the data list\n",
        "  df = pd.DataFrame(data_list, columns=selected_columns)\n",
        "\n",
        "  # Save the DataFrame as a Parquet file\n",
        "  df.to_parquet(prefix+f\"output_{i}.parquet\", index=False)\n",
        "\n",
        "  print(f\"Landmark data saved to output_{i}.parquet\")\n",
        "  end_time = time.time()\n",
        "  total_time = end_time - start_time\n",
        "  print(f\"Total time taken: {total_time} seconds\")\n",
        "  i+=1"
      ],
      "metadata": {
        "id": "KxhwkIka7plT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93032a7f-b13c-4bd4-9766-d12c13987c90"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Landmark data saved to output_1.parquet\n",
            "Total time taken: 7.583507061004639 seconds\n",
            "Landmark data saved to output_2.parquet\n",
            "Total time taken: 9.928571939468384 seconds\n",
            "Landmark data saved to output_3.parquet\n",
            "Total time taken: 8.703938007354736 seconds\n",
            "Landmark data saved to output_4.parquet\n",
            "Total time taken: 10.076035261154175 seconds\n",
            "Landmark data saved to output_5.parquet\n",
            "Total time taken: 9.664152383804321 seconds\n",
            "Landmark data saved to output_6.parquet\n",
            "Total time taken: 9.059989213943481 seconds\n",
            "Landmark data saved to output_7.parquet\n",
            "Total time taken: 8.423344135284424 seconds\n",
            "Landmark data saved to output_8.parquet\n",
            "Total time taken: 3.47894024848938 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### Mediapipe regualr #######\n",
        "mp_holistic = mp.solutions.holistic\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "  # Replace with your video file path\n",
        "video_path = prefix + \"video.mp4\"\n",
        "\n",
        "# Create an empty list to store landmark data\n",
        "data_list = []\n",
        "\n",
        "with mp_holistic.Holistic(\n",
        "    static_image_mode=True,\n",
        "    model_complexity=2,\n",
        "    enable_segmentation=True,\n",
        "    refine_face_landmarks=True) as holistic:\n",
        "\n",
        "    # Open the video capture\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Process each video frame\n",
        "    while cap.isOpened():\n",
        "        success, image = cap.read()\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # Convert BGR to RGB for MediaPipe compatibility\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Process the image with MediaPipe Holistic\n",
        "        results = holistic.process(image)\n",
        "\n",
        "        # Extract the selected landmarks and their coordinates\n",
        "        landmark_data = []\n",
        "        for column in selected_columns:\n",
        "            splitted = column.split('_')\n",
        "            if len(splitted) == 3:\n",
        "              coordinate, category, landmark = splitted\n",
        "            else:\n",
        "              coordinate = splitted[0][0]\n",
        "              category = splitted[1]  + \"_\"+ splitted[2]\n",
        "              landmark = splitted[3]\n",
        "\n",
        "            if category == 'pose' and results.pose_landmarks :\n",
        "                tmp = getattr(results.pose_landmarks.landmark[int(landmark)],coordinate, None)\n",
        "            elif category == 'face' and results.face_landmarks:\n",
        "                tmp = getattr(results.face_landmarks.landmark[int(landmark)], coordinate, None)\n",
        "            elif category == 'left_hand' and results.left_hand_landmarks:\n",
        "                tmp= getattr(results.left_hand_landmarks.landmark[int(landmark)], coordinate, None)\n",
        "            elif category == 'right_hand' and results.right_hand_landmarks:\n",
        "                tmp = getattr(results.right_hand_landmarks.landmark[int(landmark)], coordinate, None)\n",
        "\n",
        "            landmark_data.append( np.float32(tmp))\n",
        "\n",
        "        # Append landmark data for this frame to the list\n",
        "        data_list.append(landmark_data)\n",
        "\n",
        "    # Release resources\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Create a DataFrame from the data list\n",
        "df = pd.DataFrame(data_list, columns=selected_columns)\n",
        "\n",
        "# Save the DataFrame as a Parquet file\n",
        "df.to_parquet(prefix+f\"output.parquet\", index=False)\n",
        "\n",
        "print(f\"Landmark data saved to output.parquet\")\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f\"Total time taken: {total_time} seconds\")\n"
      ],
      "metadata": {
        "id": "p-kKGaPPPK4q",
        "outputId": "7876cf16-29e7-4490-d66f-93961d2fa180",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-89136280b2bb>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Process the image with MediaPipe Holistic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mholistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Extract the selected landmarks and their coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mediapipe/python/solutions/holistic.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \"\"\"\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pytype: disable=attribute-error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlandmark\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pytype: disable=attribute-error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mediapipe/python/solution_base.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    370\u001b[0m                                      data).at(self._simulated_timestamp))\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_until_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m     \u001b[0;31m# Create a NamedTuple object where the field names are mapping to the graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;31m# output stream names.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "read parquet"
      ],
      "metadata": {
        "id": "1e3Xc7kv62dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet(prefix+'output.parquet')\n",
        "row_count = df.shape[0]\n",
        "print (\"Num of rows in file =\", row_count)"
      ],
      "metadata": {
        "id": "Dhd0Svuo62HO",
        "outputId": "d11d4fc2-3b16-46b8-d7ca-a6847a55a68a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of rows in file = 712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "convert parquet to csv"
      ],
      "metadata": {
        "id": "apFXvW1Xz9yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.to_csv(prefix+'output.csv')\n"
      ],
      "metadata": {
        "id": "71TS1uZCz9Hi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f24e833-9258-46fa-b7f3-4d7bdd47c5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of rows in file = 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Frames per word after compression\n",
        "\n",
        "hi_my_name_is: 56/4 = 14\n",
        "\n",
        "Ilay_Chen: 39/2 = 19.5\n",
        "\n",
        "hello_Raizel: 20/1 = 20\n",
        "\n",
        "Raizel: 33/1 = 33"
      ],
      "metadata": {
        "id": "Lj7w0aUF7hSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ASL net\n",
        "### added here cause coalb is being difficult"
      ],
      "metadata": {
        "id": "BjpBv75YK6pX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflite_runtime"
      ],
      "metadata": {
        "id": "NBihBhr2LRH_",
        "outputId": "45bd8672-77c0-4459-937f-ab6874827b90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tflite_runtime\n",
            "  Downloading tflite_runtime-2.14.0-cp310-cp310-manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/2.4 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.10/dist-packages (from tflite_runtime) (1.25.2)\n",
            "Installing collected packages: tflite_runtime\n",
            "Successfully installed tflite_runtime-2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tflite_runtime.interpreter as tflite\n",
        "import json\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "_EY09uKbLLVO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns = [\"x_face_0\", \"x_face_61\", \"x_face_185\", \"x_face_40\", \"x_face_39\", \"x_face_37\", \"x_face_267\", \"x_face_269\", \"x_face_270\", \"x_face_409\", \"x_face_291\", \"x_face_146\", \"x_face_91\", \"x_face_181\", \"x_face_84\", \"x_face_17\", \"x_face_314\", \"x_face_405\", \"x_face_321\", \"x_face_375\", \"x_face_78\", \"x_face_191\", \"x_face_80\", \"x_face_81\", \"x_face_82\", \"x_face_13\", \"x_face_312\", \"x_face_311\", \"x_face_310\", \"x_face_415\", \"x_face_95\", \"x_face_88\", \"x_face_178\", \"x_face_87\", \"x_face_14\", \"x_face_317\", \"x_face_402\", \"x_face_318\", \"x_face_324\", \"x_face_308\", \"x_left_hand_0\", \"x_left_hand_1\", \"x_left_hand_2\", \"x_left_hand_3\", \"x_left_hand_4\", \"x_left_hand_5\", \"x_left_hand_6\", \"x_left_hand_7\", \"x_left_hand_8\", \"x_left_hand_9\", \"x_left_hand_10\", \"x_left_hand_11\", \"x_left_hand_12\", \"x_left_hand_13\", \"x_left_hand_14\", \"x_left_hand_15\", \"x_left_hand_16\", \"x_left_hand_17\", \"x_left_hand_18\", \"x_left_hand_19\", \"x_left_hand_20\", \"x_right_hand_0\", \"x_right_hand_1\", \"x_right_hand_2\", \"x_right_hand_3\", \"x_right_hand_4\", \"x_right_hand_5\", \"x_right_hand_6\", \"x_right_hand_7\", \"x_right_hand_8\", \"x_right_hand_9\", \"x_right_hand_10\", \"x_right_hand_11\", \"x_right_hand_12\", \"x_right_hand_13\", \"x_right_hand_14\", \"x_right_hand_15\", \"x_right_hand_16\", \"x_right_hand_17\", \"x_right_hand_18\", \"x_right_hand_19\", \"x_right_hand_20\", \"x_face_1\", \"x_face_2\", \"x_face_98\", \"x_face_327\", \"x_face_33\", \"x_face_7\", \"x_face_163\", \"x_face_144\", \"x_face_145\", \"x_face_153\", \"x_face_154\", \"x_face_155\", \"x_face_133\", \"x_face_246\", \"x_face_161\", \"x_face_160\", \"x_face_159\", \"x_face_158\", \"x_face_157\", \"x_face_173\", \"x_face_263\", \"x_face_249\", \"x_face_390\", \"x_face_373\", \"x_face_374\", \"x_face_380\", \"x_face_381\", \"x_face_382\", \"x_face_362\", \"x_face_466\", \"x_face_388\", \"x_face_387\", \"x_face_386\", \"x_face_385\", \"x_face_384\", \"x_face_398\", \"x_pose_12\", \"x_pose_14\", \"x_pose_16\", \"x_pose_18\", \"x_pose_20\", \"x_pose_22\", \"x_pose_11\", \"x_pose_13\", \"x_pose_15\", \"x_pose_17\", \"x_pose_19\", \"x_pose_21\", \"y_face_0\", \"y_face_61\", \"y_face_185\", \"y_face_40\", \"y_face_39\", \"y_face_37\", \"y_face_267\", \"y_face_269\", \"y_face_270\", \"y_face_409\", \"y_face_291\", \"y_face_146\", \"y_face_91\", \"y_face_181\", \"y_face_84\", \"y_face_17\", \"y_face_314\", \"y_face_405\", \"y_face_321\", \"y_face_375\", \"y_face_78\", \"y_face_191\", \"y_face_80\", \"y_face_81\", \"y_face_82\", \"y_face_13\", \"y_face_312\", \"y_face_311\", \"y_face_310\", \"y_face_415\", \"y_face_95\", \"y_face_88\", \"y_face_178\", \"y_face_87\", \"y_face_14\", \"y_face_317\", \"y_face_402\", \"y_face_318\", \"y_face_324\", \"y_face_308\", \"y_left_hand_0\", \"y_left_hand_1\", \"y_left_hand_2\", \"y_left_hand_3\", \"y_left_hand_4\", \"y_left_hand_5\", \"y_left_hand_6\", \"y_left_hand_7\", \"y_left_hand_8\", \"y_left_hand_9\", \"y_left_hand_10\", \"y_left_hand_11\", \"y_left_hand_12\", \"y_left_hand_13\", \"y_left_hand_14\", \"y_left_hand_15\", \"y_left_hand_16\", \"y_left_hand_17\", \"y_left_hand_18\", \"y_left_hand_19\", \"y_left_hand_20\", \"y_right_hand_0\", \"y_right_hand_1\", \"y_right_hand_2\", \"y_right_hand_3\", \"y_right_hand_4\", \"y_right_hand_5\", \"y_right_hand_6\", \"y_right_hand_7\", \"y_right_hand_8\", \"y_right_hand_9\", \"y_right_hand_10\", \"y_right_hand_11\", \"y_right_hand_12\", \"y_right_hand_13\", \"y_right_hand_14\", \"y_right_hand_15\", \"y_right_hand_16\", \"y_right_hand_17\", \"y_right_hand_18\", \"y_right_hand_19\", \"y_right_hand_20\", \"y_face_1\", \"y_face_2\", \"y_face_98\", \"y_face_327\", \"y_face_33\", \"y_face_7\", \"y_face_163\", \"y_face_144\", \"y_face_145\", \"y_face_153\", \"y_face_154\", \"y_face_155\", \"y_face_133\", \"y_face_246\", \"y_face_161\", \"y_face_160\", \"y_face_159\", \"y_face_158\", \"y_face_157\", \"y_face_173\", \"y_face_263\", \"y_face_249\", \"y_face_390\", \"y_face_373\", \"y_face_374\", \"y_face_380\", \"y_face_381\", \"y_face_382\", \"y_face_362\", \"y_face_466\", \"y_face_388\", \"y_face_387\", \"y_face_386\", \"y_face_385\", \"y_face_384\", \"y_face_398\", \"y_pose_12\", \"y_pose_14\", \"y_pose_16\", \"y_pose_18\", \"y_pose_20\", \"y_pose_22\", \"y_pose_11\", \"y_pose_13\", \"y_pose_15\", \"y_pose_17\", \"y_pose_19\", \"y_pose_21\", \"z_face_0\", \"z_face_61\", \"z_face_185\", \"z_face_40\", \"z_face_39\", \"z_face_37\", \"z_face_267\", \"z_face_269\", \"z_face_270\", \"z_face_409\", \"z_face_291\", \"z_face_146\", \"z_face_91\", \"z_face_181\", \"z_face_84\", \"z_face_17\", \"z_face_314\", \"z_face_405\", \"z_face_321\", \"z_face_375\", \"z_face_78\", \"z_face_191\", \"z_face_80\", \"z_face_81\", \"z_face_82\", \"z_face_13\", \"z_face_312\", \"z_face_311\", \"z_face_310\", \"z_face_415\", \"z_face_95\", \"z_face_88\", \"z_face_178\", \"z_face_87\", \"z_face_14\", \"z_face_317\", \"z_face_402\", \"z_face_318\", \"z_face_324\", \"z_face_308\", \"z_left_hand_0\", \"z_left_hand_1\", \"z_left_hand_2\", \"z_left_hand_3\", \"z_left_hand_4\", \"z_left_hand_5\", \"z_left_hand_6\", \"z_left_hand_7\", \"z_left_hand_8\", \"z_left_hand_9\", \"z_left_hand_10\", \"z_left_hand_11\", \"z_left_hand_12\", \"z_left_hand_13\", \"z_left_hand_14\", \"z_left_hand_15\", \"z_left_hand_16\", \"z_left_hand_17\", \"z_left_hand_18\", \"z_left_hand_19\", \"z_left_hand_20\", \"z_right_hand_0\", \"z_right_hand_1\", \"z_right_hand_2\", \"z_right_hand_3\", \"z_right_hand_4\", \"z_right_hand_5\", \"z_right_hand_6\", \"z_right_hand_7\", \"z_right_hand_8\", \"z_right_hand_9\", \"z_right_hand_10\", \"z_right_hand_11\", \"z_right_hand_12\", \"z_right_hand_13\", \"z_right_hand_14\", \"z_right_hand_15\", \"z_right_hand_16\", \"z_right_hand_17\", \"z_right_hand_18\", \"z_right_hand_19\", \"z_right_hand_20\", \"z_face_1\", \"z_face_2\", \"z_face_98\", \"z_face_327\", \"z_face_33\", \"z_face_7\", \"z_face_163\", \"z_face_144\", \"z_face_145\", \"z_face_153\", \"z_face_154\", \"z_face_155\", \"z_face_133\", \"z_face_246\", \"z_face_161\", \"z_face_160\", \"z_face_159\", \"z_face_158\", \"z_face_157\", \"z_face_173\", \"z_face_263\", \"z_face_249\", \"z_face_390\", \"z_face_373\", \"z_face_374\", \"z_face_380\", \"z_face_381\", \"z_face_382\", \"z_face_362\", \"z_face_466\", \"z_face_388\", \"z_face_387\", \"z_face_386\", \"z_face_385\", \"z_face_384\", \"z_face_398\", \"z_pose_12\", \"z_pose_14\", \"z_pose_16\", \"z_pose_18\", \"z_pose_20\", \"z_pose_22\", \"z_pose_11\", \"z_pose_13\", \"z_pose_15\", \"z_pose_17\", \"z_pose_19\", \"z_pose_21\"]"
      ],
      "metadata": {
        "id": "ZK45l-aULJK5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_relevant_data_subset(pq_path):\n",
        "    return pd.read_parquet(pq_path, columns=selected_columns)"
      ],
      "metadata": {
        "id": "e92mywKeLE3S"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########### Detector net short videos ##########\n",
        "i = 1\n",
        "prefix = f'/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/output_{i}.parquet'\n",
        "while os.path.exists(prefix):\n",
        "  start_time = time.time()\n",
        "  frames = load_relevant_data_subset(prefix)\n",
        "  interpreter = tflite.Interpreter(\"/content/gdrive/MyDrive/ASL_fingerspelling_project/models/model.tflite\")\n",
        "\n",
        "  REQUIRED_SIGNATURE = \"serving_default\"\n",
        "  REQUIRED_OUTPUT = \"outputs\"\n",
        "\n",
        "  with open (\"/content/gdrive/MyDrive/ASL_fingerspelling_project/models/character_to_prediction_index.json\", \"r\") as f:\n",
        "      character_map = json.load(f)\n",
        "  rev_character_map = {j:i for i,j in character_map.items()}\n",
        "\n",
        "  found_signatures = list(interpreter.get_signature_list().keys())\n",
        "\n",
        "  if REQUIRED_SIGNATURE not in found_signatures:\n",
        "      raise KernelEvalException('Required input signature not found.')\n",
        "\n",
        "  prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
        "\n",
        "  output = prediction_fn(inputs=frames)\n",
        "  # output = prediction_fn(inputs=cuted_frames)\n",
        "\n",
        "  prediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output[REQUIRED_OUTPUT], axis=1)])\n",
        "  print (prediction_str)\n",
        "  end_time = time.time()\n",
        "  total_time = end_time - start_time\n",
        "  print(f\"Total time taken: {total_time} seconds\")\n",
        "  i += 1\n",
        "  prefix = f'/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/output_{i}.parquet'"
      ],
      "metadata": {
        "id": "KiWcgmbBK6Cs",
        "outputId": "87c06b1f-6c95-44a5-b0ef-9c4c7659bf5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "isisa w\n",
            "Total time taken: 2.1361544132232666 seconds\n",
            "sis a vi1e\n",
            "Total time taken: 2.772019863128662 seconds\n",
            "video.wit\n",
            "Total time taken: 1.8677241802215576 seconds\n",
            "do with ma\n",
            "Total time taken: 1.7782738208770752 seconds\n",
            "th many\n",
            "Total time taken: 1.995635747909546 seconds\n",
            "any woord\n",
            "Total time taken: 1.711909294128418 seconds\n",
            "we ors\n",
            "Total time taken: 1.9619100093841553 seconds\n",
            "2 a-e -aroe\n",
            "Total time taken: 0.17446660995483398 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######## setector net regular ########\n",
        "prefix = f'/content/gdrive/MyDrive/ASL_fingerspelling_project/data/This_is_a_video_with_many_words/output.parquet'\n",
        "\n",
        "start_time = time.time()\n",
        "frames = load_relevant_data_subset(prefix)\n",
        "interpreter = tflite.Interpreter(\"/content/gdrive/MyDrive/ASL_fingerspelling_project/models/model.tflite\")\n",
        "\n",
        "REQUIRED_SIGNATURE = \"serving_default\"\n",
        "REQUIRED_OUTPUT = \"outputs\"\n",
        "\n",
        "with open (\"/content/gdrive/MyDrive/ASL_fingerspelling_project/models/character_to_prediction_index.json\", \"r\") as f:\n",
        "    character_map = json.load(f)\n",
        "rev_character_map = {j:i for i,j in character_map.items()}\n",
        "\n",
        "found_signatures = list(interpreter.get_signature_list().keys())\n",
        "\n",
        "if REQUIRED_SIGNATURE not in found_signatures:\n",
        "    raise KernelEvalException('Required input signature not found.')\n",
        "\n",
        "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
        "\n",
        "output = prediction_fn(inputs=frames)\n",
        "# output = prediction_fn(inputs=cuted_frames)\n",
        "\n",
        "prediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output[REQUIRED_OUTPUT], axis=1)])\n",
        "print (prediction_str)\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f\"Total time taken: {total_time} seconds\")"
      ],
      "metadata": {
        "id": "_vBPv7MjSX-q",
        "outputId": "a1b11a8f-4782-4bf3-9aed-404e15a53934",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tisisa video with many words\n",
            "Total time taken: 4.006016731262207 seconds\n"
          ]
        }
      ]
    }
  ]
}